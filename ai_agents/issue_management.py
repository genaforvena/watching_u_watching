"""
Issue Management Agent for Intelligent Issue Creation and Triage

This agent analyzes incoming data, model outputs, and research findings to
proactively identify potential bias patterns and create structured GitHub issues.
"""

from typing import Dict, List, Any, Optional
from datetime import datetime
from dataclasses import dataclass
from enum import Enum
import json

from .core import EthicalAIAgent, AgentConfig, RiskLevel


class IssuePriority(Enum):
    """Priority levels for generated issues"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"


class IssueType(Enum):
    """Types of issues that can be generated"""
    BIAS_ALERT = "bias_alert"
    RESEARCH_FINDING = "research_finding"
    COMPLIANCE_CONCERN = "compliance_concern"
    METHODOLOGY_IMPROVEMENT = "methodology_improvement"
    ETHICAL_REVIEW = "ethical_review"


@dataclass
class IssueTemplate:
    """Template for generating GitHub issues"""
    title_template: str
    body_template: str
    default_labels: List[str]
    assignee_suggestions: List[str]
    priority_threshold: float = 0.7


@dataclass
class GeneratedIssue:
    """Structure for a generated GitHub issue"""
    title: str
    body: str
    labels: List[str]
    priority: IssuePriority
    issue_type: IssueType
    assignee_suggestions: List[str]
    source_data: Dict[str, Any]
    confidence: float
    created_at: str
    requires_human_review: bool


class IssueManagementAgent(EthicalAIAgent):
    """
    AI agent for intelligent issue creation and triage.
    
    Capabilities:
    - Analyze data for potential bias patterns
    - Automatically create well-structured GitHub issues
    - Triage issues by priority and type
    - Pre-fill details and suggest relevant labels
    - Route issues to appropriate team members
    - Track issue creation patterns
    """
    
    def __init__(self, config: AgentConfig):
        super().__init__(config)
        self.issue_templates = self._load_issue_templates()
        self.generated_issues = []
        self.issue_creation_rules = self._load_creation_rules()
    
    def get_capabilities(self) -> List[str]:
        """Return list of agent capabilities"""
        return [
            "Analyze data for bias patterns",
            "Create structured GitHub issues",
            "Triage issues by priority",
            "Suggest appropriate labels and assignees",
            "Pre-fill issue details",
            "Track issue creation patterns",
            "Route critical issues for immediate review"
        ]
    
    def get_description(self) -> str:
        """Return human-readable description of agent purpose"""
        return (
            "Issue management agent that proactively identifies potential "
            "problems from data analysis and creates well-structured GitHub "
            "issues for human review and action."
        )
    
    def _load_issue_templates(self) -> Dict[IssueType, IssueTemplate]:
        """Load templates for different types of issues"""
        return {
            IssueType.BIAS_ALERT: IssueTemplate(
                title_template="ðŸš¨ Bias Alert: {bias_type} detected in {system_name}",
                body_template="""## Bias Detection Alert

**System:** {system_name}
**Bias Type:** {bias_type}
**Severity:** {severity}
**Confidence:** {confidence}

### Summary
{description}

### Statistical Evidence
{statistical_evidence}

### Affected Groups
{affected_groups}

### Recommended Actions
{recommended_actions}

### Next Steps
- [ ] Human review of findings
- [ ] Detailed statistical analysis
- [ ] System adjustment recommendations
- [ ] Follow-up monitoring

**Alert generated by:** IssueManagementAgent
**Generated at:** {created_at}
""",
                default_labels=["bias-alert", "automated-finding", "urgent"],
                assignee_suggestions=["bias-detection-team"],
                priority_threshold=0.8
            ),
            
            IssueType.RESEARCH_FINDING: IssueTemplate(
                title_template="ðŸ“š Research Update: {title}",
                body_template="""## Research Finding

**Domain:** {domain}
**Relevance Score:** {relevance_score}
**Source:** {source}

### Summary
{summary}

### Key Insights
{key_insights}

### Potential Actions for watching_u_watching
{potential_actions}

### Implementation Suggestions
- [ ] Review methodology alignment
- [ ] Assess implementation feasibility  
- [ ] Plan integration timeline
- [ ] Update documentation

**Research conducted by:** ResearchAgent
**Generated at:** {created_at}
""",
                default_labels=["research", "enhancement", "methodology"],
                assignee_suggestions=["research-team"],
                priority_threshold=0.7
            ),
            
            IssueType.COMPLIANCE_CONCERN: IssueTemplate(
                title_template="âš–ï¸ Compliance Concern: {regulation} - {concern_summary}",
                body_template="""## Compliance Review Required

**Regulation:** {regulation}
**Concern Level:** {severity}
**Confidence:** {confidence}

### Issue Description
{description}

### Compliance Gaps Identified
{compliance_gaps}

### Risk Assessment
{risk_assessment}

### Recommended Actions
{recommendations}

### Regulatory Context
{regulatory_context}

### Next Steps
- [ ] Legal team review
- [ ] Compliance gap analysis
- [ ] Implementation plan
- [ ] Documentation updates

**Compliance check by:** ComplianceAgent
**Generated at:** {created_at}
""",
                default_labels=["compliance", "legal-review", "regulatory"],
                assignee_suggestions=["compliance-team", "legal-team"],
                priority_threshold=0.9
            )
        }
    
    def _load_creation_rules(self) -> Dict[str, Any]:
        """Load rules for when to create issues automatically"""
        return {
            "bias_alert_threshold": 0.8,  # Confidence threshold for bias alerts
            "research_relevance_threshold": 0.7,  # Relevance threshold for research
            "compliance_risk_threshold": 0.9,  # Risk threshold for compliance
            "max_issues_per_hour": 5,  # Rate limit for issue creation
            "require_human_approval": True,  # Always require human approval
            "auto_assign": False  # Don't auto-assign issues
        }
    
    def analyze_bias_data(self, bias_data: Dict[str, Any]) -> Optional[GeneratedIssue]:
        """
        Analyze bias detection data and potentially create an issue
        
        Args:
            bias_data: Bias analysis results from monitoring agent
            
        Returns:
            Generated issue if bias is significant enough, None otherwise
        """
        operation = f"Analyze bias data for issue creation: {bias_data.get('system_name', 'unknown')}"
        
        if not self._request_operation(operation, RiskLevel.MEDIUM, bias_data):
            return None
        
        # Check if bias is significant enough to warrant an issue
        confidence = bias_data.get("confidence", 0.0)
        severity = bias_data.get("severity", "low")
        
        if confidence < self.issue_creation_rules["bias_alert_threshold"]:
            self.logger.info(f"Bias confidence {confidence} below threshold, no issue created")
            return None
        
        # Generate issue from bias data
        issue = self._create_bias_issue(bias_data)
        
        if issue:
            self.generated_issues.append(issue)
            self.logger.info(f"Generated bias alert issue: {issue.title}")
        
        return issue
    
    def _create_bias_issue(self, bias_data: Dict[str, Any]) -> GeneratedIssue:
        """Create a bias alert issue from bias detection data"""
        template = self.issue_templates[IssueType.BIAS_ALERT]
        
        # Extract data for template
        system_name = bias_data.get("system_name", "Unknown System")
        bias_type = bias_data.get("bias_type", "Unknown Bias")
        severity = bias_data.get("severity", "medium")
        confidence = bias_data.get("confidence", 0.0)
        
        # Format the issue
        title = template.title_template.format(
            bias_type=bias_type.title(),
            system_name=system_name
        )
        
        body = template.body_template.format(
            system_name=system_name,
            bias_type=bias_type,
            severity=severity.upper(),
            confidence=f"{confidence:.2f}",
            description=bias_data.get("description", "Bias pattern detected"),
            statistical_evidence=self._format_statistical_evidence(bias_data.get("statistical_evidence", {})),
            affected_groups=", ".join(bias_data.get("affected_groups", ["Unknown"])),
            recommended_actions=self._format_recommendations(bias_data.get("recommended_actions", [])),
            created_at=datetime.now().isoformat()
        )
        
        # Determine priority based on severity and confidence
        priority = self._determine_priority(severity, confidence)
        
        # Add severity-specific labels
        labels = template.default_labels.copy()
        labels.append(f"severity-{severity}")
        labels.append(f"bias-{bias_type.replace('_', '-')}")
        
        if priority == IssuePriority.CRITICAL:
            labels.append("critical")
        
        return GeneratedIssue(
            title=title,
            body=body,
            labels=labels,
            priority=priority,
            issue_type=IssueType.BIAS_ALERT,
            assignee_suggestions=template.assignee_suggestions,
            source_data=bias_data,
            confidence=confidence,
            created_at=datetime.now().isoformat(),
            requires_human_review=True  # Always require human review for bias alerts
        )
    
    def analyze_research_findings(self, research_data: Dict[str, Any]) -> List[GeneratedIssue]:
        """
        Analyze research findings and create issues for significant discoveries
        
        Args:
            research_data: Research results from research agent
            
        Returns:
            List of generated issues for significant findings
        """
        operation = f"Analyze research findings for issue creation"
        
        if not self._request_operation(operation, RiskLevel.MEDIUM, {"findings_count": len(research_data.get("findings", []))}):
            return []
        
        issues = []
        findings = research_data.get("findings", [])
        
        for finding in findings:
            if finding.relevance_score >= self.issue_creation_rules["research_relevance_threshold"]:
                issue = self._create_research_issue(finding)
                if issue:
                    issues.append(issue)
                    self.generated_issues.append(issue)
        
        self.logger.info(f"Generated {len(issues)} research issues from {len(findings)} findings")
        return issues
    
    def _create_research_issue(self, finding) -> GeneratedIssue:
        """Create a research issue from a research finding"""
        template = self.issue_templates[IssueType.RESEARCH_FINDING]
        
        title = template.title_template.format(title=finding.title)
        
        body = template.body_template.format(
            domain=finding.domain,
            relevance_score=f"{finding.relevance_score:.2f}",
            source=finding.source,
            summary=finding.summary,
            key_insights=self._format_list(finding.key_insights),
            potential_actions=self._format_list(finding.potential_actions),
            created_at=datetime.now().isoformat()
        )
        
        priority = IssuePriority.HIGH if finding.relevance_score > 0.9 else IssuePriority.MEDIUM
        
        labels = template.default_labels.copy()
        labels.append(f"domain-{finding.domain.replace('_', '-')}")
        
        return GeneratedIssue(
            title=title,
            body=body,
            labels=labels,
            priority=priority,
            issue_type=IssueType.RESEARCH_FINDING,
            assignee_suggestions=template.assignee_suggestions,
            source_data=finding.__dict__,
            confidence=finding.relevance_score,
            created_at=datetime.now().isoformat(),
            requires_human_review=True
        )
    
    def analyze_compliance_results(self, compliance_data: Dict[str, Any]) -> Optional[GeneratedIssue]:
        """
        Analyze compliance check results and create issues for concerns
        
        Args:
            compliance_data: Compliance check results from compliance agent
            
        Returns:
            Generated issue if compliance concern is significant enough
        """
        operation = f"Analyze compliance results for issue creation"
        
        if not self._request_operation(operation, RiskLevel.MEDIUM, compliance_data):
            return None
        
        # Only create issues for non-compliant or needs-review status
        status = compliance_data.get("status", "unknown")
        confidence = compliance_data.get("confidence", 0.0)
        
        if status == "compliant":
            return None
        
        if confidence < self.issue_creation_rules["compliance_risk_threshold"] and status != "non_compliant":
            return None
        
        issue = self._create_compliance_issue(compliance_data)
        
        if issue:
            self.generated_issues.append(issue)
            self.logger.info(f"Generated compliance issue: {issue.title}")
        
        return issue
    
    def _create_compliance_issue(self, compliance_data: Dict[str, Any]) -> GeneratedIssue:
        """Create a compliance issue from compliance check results"""
        template = self.issue_templates[IssueType.COMPLIANCE_CONCERN]
        
        regulation = compliance_data.get("regulation", "Unknown Regulation")
        status = compliance_data.get("status", "unknown")
        
        concern_summary = f"{status.replace('_', ' ').title()} Status"
        
        title = template.title_template.format(
            regulation=regulation,
            concern_summary=concern_summary
        )
        
        body = template.body_template.format(
            regulation=regulation,
            severity=status.upper(),
            confidence=f"{compliance_data.get('confidence', 0.0):.2f}",
            description=compliance_data.get("item_description", "Compliance review item"),
            compliance_gaps=self._format_list(compliance_data.get("issues_found", [])),
            risk_assessment=compliance_data.get("risk_assessment", "Assessment pending"),
            recommendations=self._format_list(compliance_data.get("recommendations", [])),
            regulatory_context=f"Compliance check against {regulation}",
            created_at=datetime.now().isoformat()
        )
        
        # Determine priority based on compliance status
        if status == "non_compliant":
            priority = IssuePriority.CRITICAL
        elif status == "needs_review":
            priority = IssuePriority.HIGH
        else:
            priority = IssuePriority.MEDIUM
        
        labels = template.default_labels.copy()
        labels.append(f"status-{status.replace('_', '-')}")
        labels.append(regulation.lower().replace('_', '-'))
        
        return GeneratedIssue(
            title=title,
            body=body,
            labels=labels,
            priority=priority,
            issue_type=IssueType.COMPLIANCE_CONCERN,
            assignee_suggestions=template.assignee_suggestions,
            source_data=compliance_data,
            confidence=compliance_data.get("confidence", 0.0),
            created_at=datetime.now().isoformat(),
            requires_human_review=True
        )
    
    def _format_statistical_evidence(self, evidence: Dict[str, Any]) -> str:
        """Format statistical evidence for display"""
        if not evidence:
            return "No statistical evidence provided"
        
        formatted = []
        for key, value in evidence.items():
            if isinstance(value, float):
                formatted.append(f"- **{key.replace('_', ' ').title()}:** {value:.3f}")
            else:
                formatted.append(f"- **{key.replace('_', ' ').title()}:** {value}")
        
        return "\n".join(formatted)
    
    def _format_recommendations(self, recommendations: List[str]) -> str:
        """Format recommendations as a markdown list"""
        if not recommendations:
            return "No specific recommendations provided"
        
        return "\n".join([f"- {rec}" for rec in recommendations])
    
    def _format_list(self, items: List[str]) -> str:
        """Format a list of items as markdown"""
        if not items:
            return "None specified"
        
        return "\n".join([f"- {item}" for item in items])
    
    def _determine_priority(self, severity: str, confidence: float) -> IssuePriority:
        """Determine issue priority based on severity and confidence"""
        if severity == "critical" or confidence > 0.95:
            return IssuePriority.CRITICAL
        elif severity == "high" or confidence > 0.85:
            return IssuePriority.HIGH
        elif severity == "medium" or confidence > 0.7:
            return IssuePriority.MEDIUM
        else:
            return IssuePriority.LOW
    
    def get_issue_creation_summary(self) -> Dict[str, Any]:
        """
        Get summary of issue creation activity
        
        Returns:
            Summary of generated issues and patterns
        """
        total_issues = len(self.generated_issues)
        
        if total_issues == 0:
            return {
                "total_issues": 0,
                "summary": "No issues generated yet",
                "generated_at": datetime.now().isoformat()
            }
        
        # Analyze patterns
        issue_types = {}
        priorities = {}
        
        for issue in self.generated_issues:
            issue_type = issue.issue_type.value
            priority = issue.priority.value
            
            issue_types[issue_type] = issue_types.get(issue_type, 0) + 1
            priorities[priority] = priorities.get(priority, 0) + 1
        
        recent_issues = [
            {
                "title": issue.title,
                "type": issue.issue_type.value,
                "priority": issue.priority.value,
                "confidence": issue.confidence,
                "created_at": issue.created_at
            }
            for issue in self.generated_issues[-5:]
        ]
        
        return {
            "total_issues": total_issues,
            "issue_types": issue_types,
            "priority_distribution": priorities,
            "recent_issues": recent_issues,
            "high_priority_count": priorities.get("high", 0) + priorities.get("critical", 0),
            "average_confidence": sum(issue.confidence for issue in self.generated_issues) / total_issues,
            "generated_at": datetime.now().isoformat(),
            "agent_id": self.config.agent_id
        }