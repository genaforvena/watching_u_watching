"""
Code Generation Agent for Implementation and Documentation Assistance

This agent provides safe, supervised code generation assistance for bias detection
tests, data preprocessing routines, and documentation while requiring human oversight.
"""

from typing import Dict, List, Any, Optional
from datetime import datetime
from dataclasses import dataclass
from enum import Enum
import json

from .core import EthicalAIAgent, AgentConfig, RiskLevel


class CodeType(Enum):
    """Types of code that can be generated"""
    BIAS_TEST = "bias_test"
    DATA_PREPROCESSING = "data_preprocessing"
    DOCUMENTATION = "documentation"
    CONFIGURATION = "configuration"
    ANALYSIS_SCRIPT = "analysis_script"


class SafetyLevel(Enum):
    """Safety levels for code generation"""
    SAFE = "safe"           # Read-only, analysis code
    REVIEW_REQUIRED = "review_required"  # Modifies data or settings
    RESTRICTED = "restricted"  # External communications or system changes


@dataclass
class CodeGenerationRequest:
    """Request for code generation"""
    description: str
    code_type: CodeType
    requirements: List[str]
    context: Dict[str, Any]
    safety_constraints: List[str]


@dataclass
class GeneratedCode:
    """Structure for generated code"""
    code: str
    documentation: str
    safety_notes: List[str]
    testing_suggestions: List[str]
    review_requirements: List[str]
    code_type: CodeType
    safety_level: SafetyLevel
    generated_at: str
    requires_human_review: bool


class CodeGenerationAgent(EthicalAIAgent):
    """
    AI agent for safe code generation assistance.
    
    Capabilities:
    - Generate bias detection test code
    - Create data preprocessing routines with ethical safeguards
    - Draft documentation based on code changes
    - Generate configuration templates
    - Create analysis scripts with safety constraints
    - Provide code review suggestions
    """
    
    def __init__(self, config: AgentConfig):
        super().__init__(config)
        self.code_templates = self._load_code_templates()
        self.safety_guidelines = self._load_safety_guidelines()
        self.generated_code_history = []
    
    def get_capabilities(self) -> List[str]:
        """Return list of agent capabilities"""
        return [
            "Generate bias detection tests",
            "Create data preprocessing routines", 
            "Draft documentation",
            "Generate configuration templates",
            "Create analysis scripts",
            "Provide code review suggestions",
            "Add safety constraints to code"
        ]
    
    def get_description(self) -> str:
        """Return human-readable description of agent purpose"""
        return (
            "Code generation agent that assists with creating safe, ethical "
            "code for bias detection and analysis while requiring human "
            "oversight for all generated code."
        )
    
    def _load_code_templates(self) -> Dict[CodeType, Dict[str, str]]:
        """Load code templates for different types of generation"""
        return {
            CodeType.BIAS_TEST: {
                "template": '''"""
Bias Detection Test: {test_name}

Generated by CodeGenerationAgent - REQUIRES HUMAN REVIEW
"""

import unittest
from typing import Dict, List, Any
import logging

# SAFETY: This test is read-only and does not modify any data
# REVIEW: Human verification required before use

class {class_name}(unittest.TestCase):
    """
    {test_description}
    
    Safety Level: {safety_level}
    Generated: {generated_at}
    """
    
    def setUp(self):
        """Set up test fixtures"""
        # SAFETY: Only using test data, no real personal information
        self.test_data = {test_data_setup}
        
    def test_{test_method_name}(self):
        """
        {test_method_description}
        """
        # SAFETY CHECK: Verify we're only using synthetic/test data
        self.assertIn("test_", str(self.test_data), "Only test data should be used")
        
        # Implement test logic here
        {test_implementation}
        
        # Log test results for transparency
        logging.info(f"Bias test completed: {{self.__class__.__name__}}")
    
    def tearDown(self):
        """Clean up after test"""
        # SAFETY: Ensure no test data persists
        self.test_data = None

if __name__ == "__main__":
    # SAFETY: Configure logging for transparency
    logging.basicConfig(level=logging.INFO)
    unittest.main()
''',
                "safety_notes": [
                    "Test uses only synthetic data",
                    "No real personal information processed",
                    "Read-only operations only",
                    "Comprehensive logging for transparency"
                ]
            },
            
            CodeType.DATA_PREPROCESSING: {
                "template": '''"""
Data Preprocessing: {preprocessing_name}

Generated by CodeGenerationAgent - REQUIRES HUMAN REVIEW
SAFETY: This code modifies data - careful review required
"""

import pandas as pd
import logging
from typing import Dict, List, Any, Optional

# SAFETY WARNING: This code modifies data
# HUMAN REVIEW REQUIRED before use

class {class_name}:
    """
    {preprocessing_description}
    
    Safety Level: {safety_level}
    Generated: {generated_at}
    
    IMPORTANT: Human review required for all data modifications
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Initialize preprocessor with safety constraints
        """
        self.config = config
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # SAFETY: Validate configuration
        self._validate_config()
    
    def _validate_config(self):
        """Validate configuration for safety"""
        required_keys = {required_config_keys}
        missing_keys = required_keys - set(self.config.keys())
        
        if missing_keys:
            raise ValueError(f"Missing required config keys: {{missing_keys}}")
        
        # SAFETY: Log configuration for transparency
        self.logger.info(f"Preprocessor initialized with config: {{self.config}}")
    
    def preprocess_data(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        {preprocessing_method_description}
        
        SAFETY: This method modifies data - ensure input is validated
        """
        # SAFETY CHECK: Validate input data
        if data is None or data.empty:
            raise ValueError("Input data cannot be None or empty")
        
        # SAFETY: Log data processing
        self.logger.info(f"Processing data with {{len(data)}} rows")
        
        # SAFETY: Create copy to avoid modifying original
        processed_data = data.copy()
        
        # Implement preprocessing logic here
        {preprocessing_implementation}
        
        # SAFETY: Validate output
        self._validate_output(processed_data)
        
        self.logger.info(f"Data preprocessing completed")
        return processed_data
    
    def _validate_output(self, data: pd.DataFrame):
        """Validate processed data for safety"""
        # SAFETY: Check for any remaining PII indicators
        pii_columns = ["email", "ssn", "phone", "address"]
        
        for col in data.columns:
            if any(pii in col.lower() for pii in pii_columns):
                self.logger.warning(f"Potential PII column detected: {{col}}")
        
        # SAFETY: Log data summary
        self.logger.info(f"Output data shape: {{data.shape}}")

# SAFETY: Example usage with explicit human review requirement
if __name__ == "__main__":
    print("HUMAN REVIEW REQUIRED: This code modifies data")
    print("Please review all processing logic before use")
    
    logging.basicConfig(level=logging.INFO)
    # Uncomment after human review:
    # preprocessor = {class_name}(config={{"example": "config"}})
''',
                "safety_notes": [
                    "Code modifies data - human review required",
                    "Input validation included",
                    "Output validation for PII detection",
                    "Comprehensive logging",
                    "Creates copy of original data"
                ]
            },
            
            CodeType.DOCUMENTATION: {
                "template": '''# {document_title}

*Generated by CodeGenerationAgent - Please review and enhance*

## Overview

{document_overview}

## Purpose

{document_purpose}

## Safety Considerations

{safety_considerations}

## Usage

{usage_instructions}

## Ethical Guidelines

This component follows the watching_u_watching ethical principles:

- **NO HARM above else**: {no_harm_compliance}
- **Transparency**: {transparency_compliance}
- **Accountability**: {accountability_compliance}
- **Human Oversight**: {human_oversight_requirements}

## Implementation Notes

{implementation_notes}

## Testing Requirements

{testing_requirements}

## Review Checklist

- [ ] Code reviewed by human developer
- [ ] Ethical compliance verified
- [ ] Safety constraints validated
- [ ] Documentation accuracy confirmed
- [ ] Testing completed

---

*Generated: {generated_at}*
*Agent: CodeGenerationAgent*
*Status: REQUIRES HUMAN REVIEW*
''',
                "safety_notes": [
                    "Documentation is informational only",
                    "No code execution involved",
                    "Requires human review for accuracy",
                    "Includes ethical compliance sections"
                ]
            }
        }
    
    def _load_safety_guidelines(self) -> Dict[str, List[str]]:
        """Load safety guidelines for code generation"""
        return {
            "general": [
                "All generated code requires human review",
                "No code should process real personal data without explicit safeguards",
                "Include comprehensive logging for transparency",
                "Add input validation for all data processing",
                "Never generate code that could cause harm"
            ],
            "bias_detection": [
                "Use only synthetic or approved test data",
                "Include statistical significance testing",
                "Add confidence intervals to results",
                "Log all test assumptions and limitations"
            ],
            "data_processing": [
                "Validate all inputs before processing",
                "Create copies of original data",
                "Include PII detection and warnings",
                "Add data quality checks"
            ],
            "external_interaction": [
                "RESTRICTED: No automated external communications",
                "RESTRICTED: No automatic data collection",
                "RESTRICTED: No system modifications without approval"
            ]
        }
    
    def generate_bias_test(self, request: CodeGenerationRequest) -> GeneratedCode:
        """
        Generate a bias detection test with safety constraints
        
        Args:
            request: Code generation request
            
        Returns:
            Generated test code with safety documentation
        """
        operation = f"Generate bias test: {request.description}"
        
        if not self._request_operation(operation, RiskLevel.MEDIUM, {"type": "bias_test"}):
            return self._create_error_response("Operation not approved")
        
        # Validate request for safety
        safety_issues = self._validate_request_safety(request)
        if safety_issues:
            self.logger.warning(f"Safety issues in request: {safety_issues}")
            return self._create_error_response(f"Safety issues: {', '.join(safety_issues)}")
        
        # Generate the test code
        template = self.code_templates[CodeType.BIAS_TEST]["template"]
        
        # Extract parameters for template
        test_name = request.description.replace(" ", "_").lower()
        class_name = f"Test{self._camel_case(test_name)}"
        
        code = template.format(
            test_name=request.description,
            class_name=class_name,
            test_description=request.description,
            safety_level=SafetyLevel.SAFE.value,
            generated_at=datetime.now().isoformat(),
            test_data_setup='"test_data": "synthetic_data_only"',
            test_method_name=test_name.replace(" ", "_"),
            test_method_description=f"Test for {request.description}",
            test_implementation="# TODO: Implement test logic (human review required)"
        )
        
        documentation = f"""
# Bias Test: {request.description}

## Generated Code Safety Analysis

**Safety Level:** {SafetyLevel.SAFE.value}
**Code Type:** Bias Detection Test
**Human Review Required:** Yes

## Safety Features Included:
- Synthetic data only
- Read-only operations
- Comprehensive logging
- Input validation
- No external communications

## Review Requirements:
- Verify test logic correctness
- Confirm use of synthetic data only
- Review statistical methods
- Validate test assumptions
"""
        
        result = GeneratedCode(
            code=code,
            documentation=documentation,
            safety_notes=self.code_templates[CodeType.BIAS_TEST]["safety_notes"],
            testing_suggestions=[
                "Run test with synthetic data only",
                "Verify statistical significance calculations",
                "Test edge cases and boundary conditions",
                "Validate test assumptions"
            ],
            review_requirements=[
                "Human developer review required",
                "Statistical methodology validation",
                "Ethical compliance verification"
            ],
            code_type=CodeType.BIAS_TEST,
            safety_level=SafetyLevel.SAFE,
            generated_at=datetime.now().isoformat(),
            requires_human_review=True
        )
        
        self.generated_code_history.append(result)
        self.logger.info(f"Generated bias test code: {test_name}")
        
        return result
    
    def generate_documentation(self, request: CodeGenerationRequest) -> GeneratedCode:
        """
        Generate documentation based on code changes or requirements
        
        Args:
            request: Documentation generation request
            
        Returns:
            Generated documentation with review requirements
        """
        operation = f"Generate documentation: {request.description}"
        
        if not self._request_operation(operation, RiskLevel.LOW, {"type": "documentation"}):
            return self._create_error_response("Operation not approved")
        
        template = self.code_templates[CodeType.DOCUMENTATION]["template"]
        
        doc_title = request.description
        
        documentation = template.format(
            document_title=doc_title,
            document_overview=f"Documentation for {request.description}",
            document_purpose=request.context.get("purpose", "Purpose to be defined"),
            safety_considerations=self._format_safety_considerations(request.safety_constraints),
            usage_instructions="Usage instructions to be added by human reviewer",
            no_harm_compliance="Compliance details to be verified by human reviewer",
            transparency_compliance="Transparency measures to be documented",
            accountability_compliance="Accountability measures to be documented", 
            human_oversight_requirements="Human oversight requirements to be specified",
            implementation_notes="Implementation notes to be added",
            testing_requirements="Testing requirements to be specified",
            generated_at=datetime.now().isoformat()
        )
        
        result = GeneratedCode(
            code=documentation,
            documentation="This is documentation generation - the 'code' field contains the generated documentation.",
            safety_notes=self.code_templates[CodeType.DOCUMENTATION]["safety_notes"],
            testing_suggestions=[
                "Review documentation accuracy",
                "Verify all sections are complete",
                "Check compliance with project standards"
            ],
            review_requirements=[
                "Human review for accuracy",
                "Compliance verification",
                "Completeness check"
            ],
            code_type=CodeType.DOCUMENTATION,
            safety_level=SafetyLevel.SAFE,
            generated_at=datetime.now().isoformat(),
            requires_human_review=True
        )
        
        self.generated_code_history.append(result)
        self.logger.info(f"Generated documentation: {doc_title}")
        
        return result
    
    def _validate_request_safety(self, request: CodeGenerationRequest) -> List[str]:
        """Validate a code generation request for safety issues"""
        issues = []
        
        # Check for restricted operations
        restricted_keywords = [
            "delete", "remove", "send_email", "external_api", 
            "production", "real_data", "personal_data"
        ]
        
        description_lower = request.description.lower()
        
        for keyword in restricted_keywords:
            if keyword in description_lower:
                issues.append(f"Restricted operation detected: {keyword}")
        
        # Check safety constraints
        if not request.safety_constraints:
            issues.append("No safety constraints specified")
        
        # Validate code type appropriateness
        if request.code_type == CodeType.DATA_PREPROCESSING:
            if "test" not in description_lower and "synthetic" not in description_lower:
                issues.append("Data preprocessing should use test/synthetic data only")
        
        return issues
    
    def _format_safety_considerations(self, constraints: List[str]) -> str:
        """Format safety constraints for documentation"""
        if not constraints:
            return "No specific safety constraints provided - human review required"
        
        return "\n".join([f"- {constraint}" for constraint in constraints])
    
    def _camel_case(self, text: str) -> str:
        """Convert text to CamelCase"""
        words = text.replace("_", " ").split()
        return "".join(word.capitalize() for word in words)
    
    def _create_error_response(self, error_message: str) -> GeneratedCode:
        """Create an error response for failed code generation"""
        return GeneratedCode(
            code=f"# ERROR: {error_message}\n# No code generated due to safety restrictions",
            documentation=f"Code generation failed: {error_message}",
            safety_notes=["Code generation blocked for safety"],
            testing_suggestions=["Review request and safety requirements"],
            review_requirements=["Address safety issues before retry"],
            code_type=CodeType.DOCUMENTATION,  # Safe default
            safety_level=SafetyLevel.RESTRICTED,
            generated_at=datetime.now().isoformat(),
            requires_human_review=True
        )
    
    def get_generation_summary(self) -> Dict[str, Any]:
        """
        Get summary of code generation activity
        
        Returns:
            Summary of generated code and safety metrics
        """
        total_generated = len(self.generated_code_history)
        
        if total_generated == 0:
            return {
                "total_generated": 0,
                "summary": "No code generated yet",
                "generated_at": datetime.now().isoformat()
            }
        
        # Analyze patterns
        code_types = {}
        safety_levels = {}
        
        for generated in self.generated_code_history:
            code_type = generated.code_type.value
            safety_level = generated.safety_level.value
            
            code_types[code_type] = code_types.get(code_type, 0) + 1
            safety_levels[safety_level] = safety_levels.get(safety_level, 0) + 1
        
        return {
            "total_generated": total_generated,
            "code_types": code_types,
            "safety_levels": safety_levels,
            "human_review_required": total_generated,  # All generated code requires review
            "restricted_generations": safety_levels.get("restricted", 0),
            "recent_generations": [
                {
                    "type": gen.code_type.value,
                    "safety_level": gen.safety_level.value,
                    "generated_at": gen.generated_at
                }
                for gen in self.generated_code_history[-5:]
            ],
            "safety_compliance": "All generated code requires human review",
            "generated_at": datetime.now().isoformat(),
            "agent_id": self.config.agent_id
        }